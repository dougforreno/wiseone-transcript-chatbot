# ğŸ”® Wiseone Transcript Chatbot

A Streamlit app for chatting with spiritual mentorship session transcripts using RAG (Retrieval-Augmented Generation).

Uses **Supabase** (pgvector) for vector storage, **OpenAI** for embeddings and chat completions.

![Streamlit](https://img.shields.io/badge/Streamlit-1.30+-red)
![OpenAI](https://img.shields.io/badge/OpenAI-GPT--4o--mini-green)
![Supabase](https://img.shields.io/badge/Supabase-pgvector-blue)

## Features

- ğŸ’¬ **Chat interface** â€” ask questions about the transcripts in natural language
- ğŸ” **Semantic search** â€” finds the most relevant transcript sections using vector embeddings
- ğŸ“– **Source citations** â€” every answer includes references to specific sessions
- ğŸ“š **23 sessions** â€” mentorship transcripts from July 2025 through February 2026
- ğŸ§  **Conversation memory** â€” maintains context within a chat session
- ğŸ’¾ **Persistent storage** â€” conversations saved to Supabase

## Quick Start

### 1. Prerequisites

- Python 3.10+
- [Supabase](https://supabase.com) project (free tier works)
- [OpenAI API key](https://platform.openai.com/api-keys)

### 2. Clone and install

```bash
git clone https://github.com/yourusername/wiseone-transcript-chatbot.git
cd wiseone-transcript-chatbot
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Configure environment

```bash
cp .env.example .env
# Edit .env with your keys
```

### 4. Run database migration

Go to your Supabase project â†’ SQL Editor â†’ paste and run `migrations/001_init.sql`.

Or via CLI:
```bash
psql $SUPABASE_DB_URL -f migrations/001_init.sql
```

### 5. Ingest transcripts

```bash
# Dry run first to see what will be processed
python scripts/ingest.py /path/to/transcripts/ --dry-run

# Actually ingest
python scripts/ingest.py /path/to/transcripts/
```

### 6. Run the app

```bash
streamlit run app.py
```

## Architecture

```
User Question
    â†“
OpenAI Embedding (text-embedding-3-small)
    â†“
Supabase pgvector similarity search
    â†“
Top-K relevant transcript chunks
    â†“
OpenAI Chat (gpt-4o-mini) with RAG context
    â†“
Answer with source citations
```

## Configuration

All settings via environment variables (see `.env.example`):

| Variable | Default | Description |
|---|---|---|
| `OPENAI_API_KEY` | â€” | Required. OpenAI API key |
| `SUPABASE_URL` | â€” | Required. Supabase project URL |
| `SUPABASE_SERVICE_KEY` | â€” | Required. Supabase service role key |
| `EMBEDDING_MODEL` | `text-embedding-3-small` | OpenAI embedding model |
| `CHAT_MODEL` | `gpt-4o-mini` | OpenAI chat model |
| `CHUNK_SIZE` | `1000` | Tokens per chunk |
| `CHUNK_OVERLAP` | `200` | Overlap between chunks |
| `TOP_K` | `5` | Number of chunks to retrieve |
| `SIMILARITY_THRESHOLD` | `0.65` | Minimum cosine similarity |

## Project Structure

```
â”œâ”€â”€ app.py                  # Streamlit application
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest.py           # Transcript ingestion script
â”œâ”€â”€ migrations/
â”‚   â””â”€â”€ 001_init.sql        # Database schema
â”œâ”€â”€ requirements.txt        # Python dependencies
â”œâ”€â”€ .env.example            # Environment template
â””â”€â”€ README.md               # This file
```

## Transcript Format

Transcripts are markdown files named `YYYY-MM-DD[-topic].md` with:
- Session date, title, participants, themes
- Key teachings and insights (structured sections)
- Full transcript text
- Optional reflections

## Cost Estimate

- **Ingestion** (one-time): ~$0.10â€“0.30 for embedding all 23 transcripts (~2.5M tokens)
- **Per query**: ~$0.001 (1 embedding + 1 chat completion)
- **Supabase**: Free tier is sufficient

## License

Private â€” for personal use only.
