# ğŸ”® Wiseone Transcript Chatbot

A Streamlit app for chatting with spiritual mentorship session transcripts using RAG (Retrieval-Augmented Generation).

Uses **Supabase** (pgvector) for vector storage, **OpenAI** for embeddings, and **OpenAI/Anthropic** for contemplative chat responses.

## Features

- ğŸ’¬ **Contemplative chat** â€” ask questions in natural language, get thoughtful, synthesized answers
- ğŸ” **Semantic search** â€” finds the most relevant transcript sections using vector embeddings
- ğŸ“– **Source citations** â€” every answer references specific sessions
- ğŸ§˜ **Two-step reflection** â€” internal contemplative synthesis before responding (mirrors Matthew's approach)
- ğŸ“š **23 sessions** â€” mentorship transcripts from July 2025 through February 2026
- ğŸ§  **Conversation memory** â€” maintains context within a chat session
- ğŸ’¾ **Persistent storage** â€” conversations saved to Supabase
- âœ¨ **Starter questions** â€” curated entry points for new users

## Voice & Approach

The chatbot embodies Matthew's teaching style:
- **Conversational, not academic** â€” like a thoughtful friend over coffee
- **Questions over answers** â€” inviting deeper inquiry
- **Comfortable with ambiguity** â€” not rushing to resolve paradoxes
- **Grounded in lived experience** â€” "how would this show up on a Tuesday?"
- **Wisdom over dogma** â€” one liberates, the other constrains

## Quick Start

### 1. Prerequisites

- Python 3.10+
- [Supabase](https://supabase.com) project (free tier works)
- [OpenAI API key](https://platform.openai.com/api-keys)
- Optional: [Anthropic API key](https://console.anthropic.com/) for Claude models

### 2. Clone and install

```bash
git clone https://github.com/dougforreno/wiseone-transcript-chatbot.git
cd wiseone-transcript-chatbot
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 3. Configure environment

```bash
cp .env.example .env
# Edit .env with your API keys
```

### 4. Run database migrations

Go to your Supabase project â†’ SQL Editor â†’ paste and run each migration:

```bash
# Migration 1: Core schema
migrations/001_init.sql

# Migration 2: Enhancements (hybrid search, themes)
migrations/002_enhancements.sql
```

### 5. Ingest transcripts

```bash
# Dry run to preview
python scripts/ingest.py /path/to/transcripts/ --dry-run

# Ingest all transcripts
python scripts/ingest.py /path/to/transcripts/

# Re-ingest a specific file
python scripts/ingest.py /path/to/transcripts/ --file 2026-02-08-nonduality-ego-awakening.md --force
```

### 6. Run the app

```bash
streamlit run app.py
```

## Architecture

```
User Question
    â†“
OpenAI Embedding (text-embedding-3-small)
    â†“
Supabase pgvector similarity search (Top-K chunks)
    â†“
Contemplative Synthesis (internal reflection step)
    â†“
Chat Response with RAG context + reflection
    â†“
Answer with source citations
```

## Configuration

Model settings and behavior are in `config.py`:

| Setting | Default | Description |
|---|---|---|
| `CHAT_MODEL` | `gpt-4o` | Chat model (supports GPT-4o, Claude) |
| `TEMPERATURE` | `0.75` | Response creativity (0.7-0.8 for contemplative) |
| `TOP_K` | `8` | Transcript chunks to retrieve |
| `SIMILARITY_THRESHOLD` | `0.30` | Minimum vector similarity |
| `CHUNK_SIZE` | `2000` | Tokens per chunk (ingestion) |
| `CHUNK_OVERLAP` | `300` | Overlap between chunks |

API keys are in `.env` (see `.env.example`).

## Project Structure

```
â”œâ”€â”€ app.py                      # Streamlit application
â”œâ”€â”€ config.py                   # Model settings, system prompt, starter questions
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ ingest.py               # Transcript ingestion script
â”œâ”€â”€ migrations/
â”‚   â”œâ”€â”€ 001_init.sql            # Core database schema
â”‚   â””â”€â”€ 002_enhancements.sql    # Hybrid search, theme index
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ .env.example                # Environment template
â””â”€â”€ README.md
```

## Database Schema

### Tables

- **transcripts** â€” Metadata for each session (date, title, themes, full content)
- **transcript_chunks** â€” Chunked text with vector embeddings for search
- **conversations** â€” Chat session records
- **messages** â€” Individual chat messages with source citations

### Key Functions

- `match_transcript_chunks()` â€” Pure vector similarity search
- `match_transcript_chunks_hybrid()` â€” Combined vector + full-text search
- `get_all_themes()` â€” Aggregate themes across all sessions

## Transcript Format

Markdown files named `YYYY-MM-DD[-topic].md` containing:
- Session metadata (date, title, participants, themes)
- Key teachings and insights
- Full transcript text
- Optional reflections

## Cost Estimate

- **Ingestion** (one-time): ~$0.10â€“0.30 for embedding all 23 transcripts
- **Per query**: ~$0.003 (1 embedding + contemplative synthesis + chat completion)
- **Supabase**: Free tier is sufficient

## License

Private â€” for personal use only.
